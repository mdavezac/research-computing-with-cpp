<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <title>GPU-accelerated Libraries</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="http://lab.hakim.se/reveal-js/css/reveal.min.css"/>
    <style type="text/css">code{white-space: pre;}</style>
    <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #303030; color: #cccccc; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; }
td.sourceCode { padding-left: 5px; }
pre, code { color: #cccccc; background-color: #303030; }
code > span.kw { color: #f0dfaf; }
code > span.dt { color: #dfdfbf; }
code > span.dv { color: #dcdccc; }
code > span.bn { color: #dca3a3; }
code > span.fl { color: #c0bed1; }
code > span.ch { color: #dca3a3; }
code > span.st { color: #cc9393; }
code > span.co { color: #7f9f7f; }
code > span.ot { color: #efef8f; }
code > span.al { color: #ffcfaf; }
code > span.fu { color: #efef8f; }
code > span.er { color: #c3bf9f; }
    </style>
    <link rel="stylesheet" href="http://lab.hakim.se/reveal-js/css/theme/night.css"/>
    <link rel="stylesheet" href="/research-computing-with-cpp//css/ucl_reveal.css"/>
    <link rel="stylesheet" href="/research-computing-with-cpp//site-styles/reveal.css"/>
  <link rel="stylesheet" media="print" href="http://lab.hakim.se/reveal-js/css/print/pdf.css" />
  <!--[if lt IE 9]>
  <script src="http://lab.hakim.se/reveal-js/lib/js/html5shiv.js"></script>
  <![endif]-->
</head>
<body>
  <div class="reveal">
    <div class="slides">

<section>
    <h1 class="title">GPU-accelerated Libraries</h1>
    <h3 class="date"></h3>
</section>

<section><section id="gpu-accelerated-libraries" class="titleslide slide level2"><h1>GPU-accelerated Libraries</h1></section><section id="cuda-libraries" class="slide level3">
<h1>CUDA Libraries</h1>
<ul>
<li>There are GPU-accelerated libraries available for:
<ul>
<li>random number generation</li>
<li>fast Fourier transforms</li>
<li>BLAS/LAPACK</li>
<li>sparse linear algebra</li>
</ul></li>
<li>Nvidia ships cuRAND, cuFFT and cuBLAS with the CUDA toolkit
<ul>
<li>3rd party alternatives including MAGMA</li>
</ul></li>
</ul>
</section><section id="converting-existing-code" class="slide level3">
<h1>Converting existing code</h1>
<ul>
<li>Each library contains pre-written GPU kernels implementing common operations optimised for several classes of GPU</li>
<li>All that is required is to convert existing code that calls a CPU library to follow the upload/execute/synchronise/download pattern
<ul>
<li>allocate GPU memory and upload data using the CUDA runtime library</li>
<li>execute pre-written kernel from the specific CUDA library required</li>
<li>synchronize, download results and free GPU memory using the CUDA runtime library</li>
</ul></li>
</ul>
</section><section id="saxpy-from-cublas" class="slide level3">
<h1>SAXPY from cuBLAS</h1>
<ul>
<li>The following code snippet replaces the <code>saxpy_fast</code> function with the equivalent <code>cublasSaxpy</code>:</li>
</ul>
<pre class="sourceCode cpp"><code class="sourceCode cpp">
    <span class="co">// Allocate vectors on GPU</span>
    <span class="dt">float</span> * dx, * dy;
    CUDA_ERROR_CHECK(cudaMalloc((<span class="dt">void</span> **)&amp;dx, n * incx * <span class="kw">sizeof</span>(<span class="dt">float</span>)));
    CUDA_ERROR_CHECK(cudaMalloc((<span class="dt">void</span> **)&amp;dy, n * incy * <span class="kw">sizeof</span>(<span class="dt">float</span>)));

    <span class="co">// Create CUBLAS handle</span>
    cublasHandle_t handle;
    CUBLAS_ERROR_CHECK(cublasCreate(&amp;handle));

    <span class="co">// Copy vectors into GPU memory</span>
    CUBLAS_ERROR_CHECK(cublasSetVector(n, <span class="kw">sizeof</span>(<span class="dt">float</span>), x, incx, dx, incx));
    CUBLAS_ERROR_CHECK(cublasSetVector(n, <span class="kw">sizeof</span>(<span class="dt">float</span>), y, incy, dy, incy));

    <span class="co">// Perform the GPU SAXPY</span>
    CUBLAS_ERROR_CHECK(cublasSaxpy(handle, n, &amp;a, dx, incx, dy, incy));

    <span class="co">// Copy results back into CPU memory</span>
    CUBLAS_ERROR_CHECK(cublasGetVector(n, <span class="kw">sizeof</span>(<span class="dt">float</span>), dy, incy, y, incy));</code></pre>
<pre><code>n = 10000, incx = 1, incy = 1
saxpy: 0.010205ms
saxpy_fast: 0.002530ms</code></pre>
</section><section id="why-isnt-it-faster" class="slide level3">
<h1>Why isn't it faster?</h1>
<ul>
<li>GPUs have about 100x the computing power of a CPU
<ul>
<li>but only 20x the memory bandwidth</li>
<li>and data transfer over the PCI bus is sloooow.</li>
</ul></li>
<li>SAXPY performs one floating point operation for each element in memory
<ul>
<li>the performance is bound by the memory bandwidth</li>
</ul></li>
<li>Matrix Multiply (SGEMM), however, performs <code>2k</code> operations per element
<ul>
<li>matrix multiply: <code>C = a*A*B + b*C</code></li>
<li><code>A</code> is <code>m</code> by <code>k</code></li>
<li><code>B</code> is <code>k</code> by <code>n</code></li>
<li><code>C</code> is <code>m</code> by <code>n</code></li>
</ul></li>
</ul>
</section><section id="sgemm-from-cublas" class="slide level3">
<h1>SGEMM from cuBLAS</h1>
<ul>
<li>CUBLAS contains an SGEMM function:</li>
</ul>
<pre class="sourceCode cpp"><code class="sourceCode cpp">
    <span class="co">// Allocate matrices on GPU</span>
    <span class="dt">float</span> * dA, * dB, * dC;
    size_t dlda, dldb, dldc;
    CUDA_ERROR_CHECK(cudaMallocPitch((<span class="dt">void</span> **)&amp;dA, &amp;dlda, m * <span class="kw">sizeof</span>(<span class="dt">float</span>), k));
    CUDA_ERROR_CHECK(cudaMallocPitch((<span class="dt">void</span> **)&amp;dB, &amp;dldb, k * <span class="kw">sizeof</span>(<span class="dt">float</span>), n));
    CUDA_ERROR_CHECK(cudaMallocPitch((<span class="dt">void</span> **)&amp;dC, &amp;dldc, m * <span class="kw">sizeof</span>(<span class="dt">float</span>), n));

    <span class="co">// cudaMallocPitch returns leading dimensions in bytes while CUBLAS expects</span>
    <span class="co">// them as number of elements</span>
    dlda /= <span class="kw">sizeof</span>(<span class="dt">float</span>);
    dldb /= <span class="kw">sizeof</span>(<span class="dt">float</span>);
    dldc /= <span class="kw">sizeof</span>(<span class="dt">float</span>);

    <span class="co">// Create CUBLAS handle</span>
    cublasHandle_t handle;
    CUBLAS_ERROR_CHECK(cublasCreate(&amp;handle));

    <span class="co">// Copy matrices into GPU memory</span>
    CUBLAS_ERROR_CHECK(cublasSetMatrix(m, k, <span class="kw">sizeof</span>(<span class="dt">float</span>), A, lda, dA, dlda));
    CUBLAS_ERROR_CHECK(cublasSetMatrix(k, n, <span class="kw">sizeof</span>(<span class="dt">float</span>), B, ldb, dB, dldb));
    CUBLAS_ERROR_CHECK(cublasSetMatrix(m, n, <span class="kw">sizeof</span>(<span class="dt">float</span>), C, ldc, dC, dldc));

    <span class="co">// Perform the GPU SGEMM</span>
    CUBLAS_ERROR_CHECK(cublasSgemm(handle,
                                   CUBLAS_OP_N, CUBLAS_OP_N,
                                   m, n, k,
                                   &amp;a, dA, dlda, dB, dldb,
                                   &amp;b, dC, dldc));

    <span class="co">// Copy results back into CPU memory</span>
    CUBLAS_ERROR_CHECK(cublasGetMatrix(m, n, <span class="kw">sizeof</span>(<span class="dt">float</span>), dC, dldc, C, ldc));</code></pre>
<pre><code>m = 320, n = 640, k = 640
Bandwidth: 977.532GB/s
Throughput: 244.383GFlops/s</code></pre>
</section></section>
    </div>
  </div>

  <script src="http://lab.hakim.se/reveal-js/lib/js/head.min.js"></script>
  <script src="http://lab.hakim.se/reveal-js/js/reveal.min.js"></script>

  <script>

      // Full list of configuration options available here:
      // https://github.com/hakimel/reveal.js#configuration
      Reveal.initialize({
        controls: true,
        progress: true,
        history: true,
        center: true,
        theme: 'night', // available themes are in /css/theme
        transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

        // Optional libraries used to extend on reveal.js
        dependencies: [
          { src: 'http://lab.hakim.se/reveal-js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
          { src: 'http://lab.hakim.se/reveal-js/plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
          { src: 'http://lab.hakim.se/reveal-js/plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } },
//          { src: 'http://lab.hakim.se/reveal-js/plugin/search/search.js', async: true, condition: function() { return !!document.body.classList; }, }
//          { src: 'http://lab.hakim.se/reveal-js/plugin/remotes/remotes.js', async: true, condition: function() { return !!document.body.classList; } }
]});
    </script>
  </body>
</html>
